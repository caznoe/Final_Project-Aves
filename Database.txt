For the database for the Aves project, the following steps were taken to set up the database:
- Gathering csv data files for bird observations from Cornell Lab of Ornithology and obtained through the Global Biodiversity Information Facility. 
- The air quality data was obtained from the United States Environmental Protection Agency. 
- Deciding the scope of the data. The initial bird observation in California file was over 47 mil rows. 
  After considering which birds that are native to California and may be more susceptible to air quality factors, 
  I requested datasets for the 14 observed species of hummingbirds in California for the last ten years. This dataset 
  produced over 1.3 million rows. 
 - For the ETL process, I used Jupyter Notebooks, Python and Pandas to merge the data sets and clean the data. 
 - In order to join the sets, an API call was used on the Federal Communication Commission site. County names were called for over 93,000 location points from the ebird dataset.
 - I set up the database in AWS and used PGAdmin to edit tables.
 - In Colabs, I used Pyspark to read in the cleaned data from AWS S3 and then loaded the data into the database on AWS. 
 - Further work in the database will be done using PGAdmin including the tables join based on location and date data.

Data Citations
Global Biodiversity Information Facility, Citation GBIF.org (10 October 2020) GBIF Occurrence Download https://doi.org/10.15468/dl.2rhbnh
Global Biodiversity Information Facility, Citation GBIF.org (10 October 2020) GBIF Occurrence Download https://doi.org/10.15468/dl.fsvwgj
